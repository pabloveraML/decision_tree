{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos todas las bibliotecas necesarias para ejecutar todos los métodos del jupyter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es buena costumbre cargarlos al principio, asi no se estar cargando en memoria repetidas veces cada paquete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "#import pydotplus\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(df, column):\n",
    "    q1 = df_final[column].quantile(.25)\n",
    "    q2 = df_final[column].quantile(.5)\n",
    "    q3 = df_final[column].quantile(.75)\n",
    "    df[column+\"_in_q1\"] = 0\n",
    "    df[column+\"_in_q2\"] = 0\n",
    "    df[column+\"_in_q3\"] = 0\n",
    "    df[column+\"_in_q4\"] = 0\n",
    "    df[column+\"_in_q1\"] = list(map(lambda x: 1 if x <=q1 else 0, df[column]))\n",
    "    df[column+\"_in_q2\"] = list(map(lambda x: 1 if (q1 < x and x <=q2) else 0, df[column]))\n",
    "    df[column+\"_in_q3\"] = list(map(lambda x: 1 if (q2 < x and x <=q3) else 0, df[column]))\n",
    "    df[column+\"_in_q4\"] = list(map(lambda x: 1 if x>q3 else 0, df[column]))\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_object(df,column,object_name):\n",
    "    df[\"is_\"+str(object_name)] = list(map(lambda x: 1 if x == object_name else 0, df[column]))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_replace_nans(df,col,rate_to_complete):\n",
    "    \n",
    "    index_list = df[col][df[col].isnull()].sample(frac=rate_to_complete,random_state=1).index.tolist()\n",
    "    \n",
    "    if len(index_list)>0:\n",
    "        moda = df[(~df[col].isnull())][col].mode()[0]\n",
    "        df.loc[index_list,col] = moda\n",
    "        print(\"Completando columna \" + str(col))\n",
    "        print(\"Moda: \" + str(moda))\n",
    "        print(\"Cantidad restante de NULLs en columna \" + str(col) + \": \"+str(df[col][df[col].isnull()].shape))\n",
    "        \n",
    "    return df\n",
    "    \n",
    "def complete_nans(df,null_cols,rate_to_complete,method):\n",
    "    if method==\"moda_por_clase\":\n",
    "        for col in null_cols:\n",
    "            print(\"Completando clase 0\")\n",
    "            df0 = find_and_replace_nans(df[df.target==0.0],col,rate_to_complete)\n",
    "            print(\"Completando clase 1\")\n",
    "            df1 = find_and_replace_nans(df[df.target==1.0],col,rate_to_complete)\n",
    "            df = pd.concat([df0,df1])\n",
    "    else:\n",
    "        for col in null_cols:\n",
    "            df = find_and_replace_nans(df,col,rate_to_complete)\n",
    "    \n",
    "    return df.dropna()\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, metodo, rate_to_complete):\n",
    "    \n",
    "    # Extraemos las filas de la columna 'model' que tienen valores NaNs y luego los completamos con un valor por defecto\n",
    "    \n",
    "    #model_null_indexes = df[df.model.isnull()].index.tolist()\n",
    "    #df.loc[model_null_indexes,\"model\"] = \"other other\"\n",
    "    \n",
    "    df['model'] = df['model'].fillna('other other')\n",
    "    \n",
    "    # Obtenemos las columnas que tienen al menos un NaN\n",
    "    cols_in_null = df.columns[df.isnull().sum(axis=0)>0].tolist()\n",
    "    \n",
    "    # Los completamos con un rate_to_complete y utilizando un determinado metodo\n",
    "    df_comp = complete_nans(df,cols_in_null,rate_to_complete,metodo)\n",
    "    \n",
    "    # Discretizamos las columnas que ya sabemos que tienen una distribucion dada (Chi, Normal)\n",
    "    # (Se usan cuantiles para ver en qué segmento caen)\n",
    "    for column in [\"diff_time_days_minnone\",\"diff_time_dayssearch engine hit\",\"COUNT(users_logs)\",\"number_visits_model\",\"diff_time_daysbrand listing\",\"diff_time_daysnone\"]:\n",
    "        df_comp = discretize(df_comp,column)\n",
    "    \n",
    "    # De la columna 'model' extraemos marca y modelo del celular visitado o  comprado\n",
    "    df_comp[\"marca\"] = df_comp.model.str.split(\" \",1,expand=True)[0]\n",
    "    df_comp[\"modelo\"] = df_comp.model.str.split(\" \",1,expand=True)[1]\n",
    "    \n",
    "    # Determinamos de que marca se trata\n",
    "    df_comp[\"is_iphone\"] = list(map(lambda x: 1 if x==\"iPhone\" else 0, df_comp[\"marca\"]))\n",
    "    df_comp[\"is_samsung\"] = list(map(lambda x: 1 if x==\"Samsung\" else 0, df_comp[\"marca\"]))\n",
    "    df_comp[\"is_motorola\"] = list(map(lambda x: 1 if x==\"Motorola\" else 0, df_comp[\"marca\"]))\n",
    "    df_comp[\"is_lg\"] = list(map(lambda x: 1 if x==\"LG\" else 0, df_comp[\"marca\"]))\n",
    "    df_comp[\"is_sony\"] = list(map(lambda x: 1 if x==\"Sony\" else 0, df_comp[\"marca\"]))\n",
    "    df_comp[\"is_other\"] = list(map(lambda x: 1 if (x!=\"Sony\" and x!=\"LG\" and x!=\"Motorola\" and x!=\"Samsung\" and x!=\"iPhone\") else 0, df_comp[\"marca\"]))\n",
    "    \n",
    "    # determinamos de que modelo se trata\n",
    "    pop_models = ['6','5s','6S','Galaxy J5','7','7 Plus','Galaxy S8','Galaxy S7','Galaxy S7 Edge','Galaxy J7 Prime','Moto G2 3G Dual','Galaxy S6 Edge','Galaxy S6 Flat','5c','6S Plus','Galaxy J7','6 Plus','Moto G4 Plus','SE','Galaxy Gran Prime Duos TV','4S','Galaxy S8 Plus','5','Moto G3 4G','Galaxy A5 2017','Moto X Play 4G Dual','Moto G5 Plus','Galaxy A7 2017','Moto X2','Galaxy A5']\n",
    "    for model in pop_models:\n",
    "        df_comp = is_object(df_comp,\"modelo\",model)\n",
    "\n",
    "    df_comp[\"is_other_model\"] = list(map(lambda x: 1 if x not in pop_models else 0, df_comp[\"modelo\"]))\n",
    "    \n",
    "    # Eliminamos las columnas con strings\n",
    "    df_comp.drop([\"model\",\"marca\",\"modelo\"],axis=1,inplace=True)\n",
    "    \n",
    "    return df_comp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datasets para construir el dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = pd.read_csv('../../data_aa/first_part_dataset.csv')\n",
    "\n",
    "df_second = pd.read_csv('../../data_aa/second_part_dataset.csv')\n",
    "\n",
    "df_thrid = pd.read_csv('../../data_aa/thrid_part_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = df_first.rename(columns={'person_id': 'person'})\n",
    "\n",
    "df_first = df_first.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'person', 'diff_time_days_minnone',\n",
       "       'diff_time_daysnone', 'diff_time_dayscheckout',\n",
       "       'diff_time_daysconversion', 'diff_time_daysbrand listing',\n",
       "       'diff_time_dayssearch engine hit', 'diff_time_start_end', 'model',\n",
       "       'number_visits_model'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_second.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second = df_second.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'person', 'COUNT(users_logs)', 'avg_time_events'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrid.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thrid = df_thrid.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_first, df_second, on='person', how='left')\n",
    "\n",
    "df_final = pd.merge(df_final, df_thrid, on='person', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19414,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.target.isin([1.0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significado de las columnas:\n",
    "\n",
    " - Las columnas 'Android', 'BlackBerry', 'Chrome', 'FreeBSD', 'Linux', 'Mac', 'Tizen', 'Ubuntu', 'Unknown', 'Windows','iOS' indican la cantidad de veces que cada usuario ingreso a la pagina de Trocafone utilizando uno de esos esos sistemas operativos. Por ejemplo, si el valor de 'Android' para un usuario es 2 siginfica que ese usuario entro a la pagina dos veces desde un dispositivo con un sistema operativo Android\n",
    " \n",
    " - Las columnas 'Computer', 'Smartphone', 'Tablet' indican la cantidad de veces que cada usuario ingreso a la pagina de Trocafone utilizando uno de esos dispositivos\n",
    " \n",
    " - Las columnas 'ad campaign hit', 'brand listing', 'checkout', 'conversion', 'generic listing', 'lead','search engine hit', 'searched products', 'staticpage','viewed product', 'visited site' indican la cantidad de veces que cada usuario realizo cada uno de esos eventos\n",
    " \n",
    " - La columna 'diff_time_days_minnone' indica la cantidad de tiempo que paso desde el primer evento que realizo el usuario hasta el 2018/06/01\n",
    " \n",
    " - La columna 'diff_time_daysnone' indica la cantidad de tiempo que paso desde el ultimo evento que el usuario realizo en la pagina hasta el 2018/06/01\n",
    " \n",
    " - La columna 'diff_time_dayscheckout' indica la cantidad de tiempo que paso desde que el usuario realizo el ultimo checkout hasta el 2018/06/01\n",
    " \n",
    " - La columna 'diff_time_daysconversion' indica la cantidad de tiempo que paso desde que el usuario realizo la ultima conversion hasta el 2018/06/01\n",
    " \n",
    " - La columna 'diff_time_daysbrand listing' indica la cantidad de tiempo que paso desde que el usuario realizo la ultima brand listing hasta el 2018/06/01\n",
    " \n",
    " - La columna 'diff_time_dayssearch engine hit' indica la cantidad de tiempo que paso desde que el usuario realizo el ultimo engine hit hasta el 2018/06/01\n",
    " \n",
    " - La columna 'diff_time_start_end' indica la cantidad de tiempo que paso entre el primer evento que realizo el usuario en la pagina y el ultimo\n",
    " \n",
    " - La columna 'model' indica el modelo de celuar que el usuario mas veces visito\n",
    " \n",
    " - La columna 'number_visits_model' indica cuantas veces el usuario visito el celular que mas visito\n",
    " \n",
    " - La columna 'COUNT(users_logs)' indica la cantidad de eventos que el usuario realizo en la pagina\n",
    " \n",
    " - La columna 'avg_time_events' indica el tiempo promedio que paso entre los eventos realizados por cada usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos las columnas con muy pocas variables o alta corrleación (Ej. Windows ~ Computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop([\"BlackBerry\",\"Chrome\",\"FreeBSD\",\"Linux\",\"Mac\",\"Other\",\"Tizen\",\"Ubuntu\",\"Unknown\",\"Windows\",\"person\"],\n",
    "              axis=1,\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformamos algunas columnas para que su distribución se ajuste a una Chi cuadrado o Normal. Luego discretizamos por cuantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[:,\"diff_time_daysnone\"] = np.log10(df_final[\"diff_time_daysnone\"]+1.)\n",
    "df_final.loc[:,\"diff_time_days_minnone\"] = np.log10(df_final.diff_time_days_minnone+1.)\n",
    "df_final.loc[:,\"diff_time_dayssearch engine hit\"] = np.log10(df_final[\"diff_time_dayssearch engine hit\"]+1.0)\n",
    "df_final.loc[:,\"COUNT(users_logs)\"] = np.log10(df_final[\"COUNT(users_logs)\"]+1.)\n",
    "df_final.loc[:,\"number_visits_model\"] = np.log10(1.+df_final.number_visits_model)\n",
    "df_final.loc[:,\"diff_time_daysbrand listing\"] = np.log10(01.+df_final[\"diff_time_daysbrand listing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         NaN\n",
       "1                    iPhone 7\n",
       "2                   iPhone 6S\n",
       "3    Motorola Moto G2 3G Dual\n",
       "4      Samsung Galaxy S8 Plus\n",
       "Name: model, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['model'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En el siguiente metodo  se realiza todo el preprocess de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completando columna diff_time_dayscheckout\n",
      "Moda: 2.2\n",
      "Cantidad restante de NULLs en columna diff_time_dayscheckout: (0,)\n",
      "Completando columna diff_time_daysconversion\n",
      "Moda: 1.2\n",
      "Cantidad restante de NULLs en columna diff_time_daysconversion: (0,)\n",
      "Completando columna diff_time_daysbrand listing\n",
      "Moda: 0.11394335230683679\n",
      "Cantidad restante de NULLs en columna diff_time_daysbrand listing: (0,)\n",
      "Completando columna diff_time_dayssearch engine hit\n",
      "Moda: 0.11394335230683679\n",
      "Cantidad restante de NULLs en columna diff_time_dayssearch engine hit: (0,)\n",
      "Completando columna number_visits_model\n",
      "Moda: 0.3010299956639812\n",
      "Cantidad restante de NULLs en columna number_visits_model: (0,)\n",
      "Completando columna avg_time_events\n",
      "Moda: 0.0\n",
      "Cantidad restante de NULLs en columna avg_time_events: (0,)\n"
     ]
    }
   ],
   "source": [
    "df_completo = preprocess(df_final.copy(),\"moda\",1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a seleccionar solo 980 casos que no realizaron una compra para balancear el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n"
     ]
    }
   ],
   "source": [
    "df_completo_reduced_1 = df_completo[df_completo['target']==1]\n",
    "print(len(df_completo_reduced_1.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n"
     ]
    }
   ],
   "source": [
    "df_completo_reduced_0 = df_completo[df_completo['target']==0].sample(n=980, random_state=1)\n",
    "print(len(df_completo_reduced_0.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_completo_reduced_1, df_completo_reduced_0])\n",
    "del df_completo_reduced_0, df_completo_reduced_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nos quedamos con aquellas columnas que no sean target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = list(set(df_train.columns.tolist())-set([\"target\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos el dataset de test y lo eliminamos del dataset de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_train.sample(frac=0.2, random_state=2)\n",
    "df_train.drop(df_test.index,axis=0,inplace=True)\n",
    "train_indexes = df_train.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificamos el balance de categorías en cada datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = df_train.shape[0]*1.\n",
    "N_test = df_test.shape[0]*1.\n",
    "\n",
    "N_train_1 = df_train.target.sum()\n",
    "N_train_0 = df_train.shape[0]*1.-N_train_1\n",
    "\n",
    "N_test_1 = df_test.target.sum()\n",
    "N_test_0 = df_test.shape[0]*1.-N_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de casos positivos en el train: %50.255102040816325\n",
      "Porcentaje de casos positivos en el test: %48.97959183673469\n"
     ]
    }
   ],
   "source": [
    "print(\"Porcentaje de casos positivos en el train: %\" + str(100.0*N_train_1/N_train))\n",
    "print(\"Porcentaje de casos positivos en el test: %\" + str(100.0*N_test_1/N_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando únicamente el dataset de train ejecutamos 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy','roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=3, criterion='gini') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(dtree, # Instancia de árbol a entrenar en cada fold\n",
    "                        df_train[feature_columns].values, # X_train features\n",
    "                        df_train[\"target\"].values, # Y_train targets\n",
    "                        scoring=scoring, # Pedimos que para fold se ejecute esta lista de scorings\n",
    "                        return_train_score = True, # Queremos ver los scorings de los training folds\n",
    "                        return_estimator = True, # Ademas, pedimos que se nos devuelvan los dtrees de entrenados\n",
    "                        cv=5, # Establecemos la cantidad de particiones para realizar la Validación cruzada\n",
    "                        n_jobs = -1 # Pedimos que se ejecute en paralelo, utilizando todos los cores\n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los resultados en un DF de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_5_fold_resultados = pd.DataFrame(scores)\n",
    "cv_5_fold_resultados.drop([\"fit_time\",\"score_time\",\"estimator\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.732484</td>\n",
       "      <td>0.767145</td>\n",
       "      <td>0.791728</td>\n",
       "      <td>0.828612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767516</td>\n",
       "      <td>0.763955</td>\n",
       "      <td>0.836356</td>\n",
       "      <td>0.824302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.779904</td>\n",
       "      <td>0.753185</td>\n",
       "      <td>0.842019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.760383</td>\n",
       "      <td>0.768127</td>\n",
       "      <td>0.802344</td>\n",
       "      <td>0.833754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766773</td>\n",
       "      <td>0.764143</td>\n",
       "      <td>0.812388</td>\n",
       "      <td>0.830726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  train_accuracy  test_roc_auc  train_roc_auc\n",
       "0       0.732484        0.767145      0.791728       0.828612\n",
       "1       0.767516        0.763955      0.836356       0.824302\n",
       "2       0.707006        0.779904      0.753185       0.842019\n",
       "3       0.760383        0.768127      0.802344       0.833754\n",
       "4       0.766773        0.764143      0.812388       0.830726"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5_fold_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos los estadisticos de cada experimento, tanto para train como para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.746833</td>\n",
       "      <td>0.768655</td>\n",
       "      <td>0.799200</td>\n",
       "      <td>0.831883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026463</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.763955</td>\n",
       "      <td>0.753185</td>\n",
       "      <td>0.824302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.732484</td>\n",
       "      <td>0.764143</td>\n",
       "      <td>0.791728</td>\n",
       "      <td>0.828612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.760383</td>\n",
       "      <td>0.767145</td>\n",
       "      <td>0.802344</td>\n",
       "      <td>0.830726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.766773</td>\n",
       "      <td>0.768127</td>\n",
       "      <td>0.812388</td>\n",
       "      <td>0.833754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.767516</td>\n",
       "      <td>0.779904</td>\n",
       "      <td>0.836356</td>\n",
       "      <td>0.842019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_accuracy  train_accuracy  test_roc_auc  train_roc_auc\n",
       "count       5.000000        5.000000      5.000000       5.000000\n",
       "mean        0.746833        0.768655      0.799200       0.831883\n",
       "std         0.026463        0.006549      0.030568       0.006629\n",
       "min         0.707006        0.763955      0.753185       0.824302\n",
       "25%         0.732484        0.764143      0.791728       0.828612\n",
       "50%         0.760383        0.767145      0.802344       0.830726\n",
       "75%         0.766773        0.768127      0.812388       0.833754\n",
       "max         0.767516        0.779904      0.836356       0.842019"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5_fold_resultados.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos el árbol que mejor accuracy haya tenido durante el train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtree_index = np.argmax(scores[\"test_accuracy\"]*scores[\"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_btree = scores[\"estimator\"][best_dtree_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos su accuracy sobre el 20% restante del dataset que no formó parte del 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_esperado = df_test.target.values\n",
    "y_pred = best_btree.predict(df_test[feature_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score validation: 0.7831632653061225\n"
     ]
    }
   ],
   "source": [
    "print(\"Score validation: \" + str(accuracy_score(y_esperado, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = StringIO()\n",
    "# export_graphviz(best_btree, out_file=dot_data,  \n",
    "#                 filled=True, rounded=True,\n",
    "#                 special_characters=True)\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volvemos a correr el 5-fold CV pero completado el dataset de train con un dado porcentaje de completitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completando columna diff_time_dayscheckout\n",
      "Moda: 0.3\n",
      "Cantidad restante de NULLs en columna diff_time_dayscheckout: (406,)\n",
      "Completando columna diff_time_daysconversion\n",
      "Moda: 1.0\n",
      "Cantidad restante de NULLs en columna diff_time_daysconversion: (1003,)\n",
      "Completando columna diff_time_daysbrand listing\n",
      "Moda: 0.07918124604762482\n",
      "Cantidad restante de NULLs en columna diff_time_daysbrand listing: (490,)\n",
      "Completando columna diff_time_dayssearch engine hit\n",
      "Moda: 0.07918124604762482\n",
      "Cantidad restante de NULLs en columna diff_time_dayssearch engine hit: (287,)\n",
      "Completando columna number_visits_model\n",
      "Moda: 0.3010299956639812\n",
      "Cantidad restante de NULLs en columna number_visits_model: (46,)\n",
      "Completando columna avg_time_events\n",
      "Moda: 0.0\n",
      "Cantidad restante de NULLs en columna avg_time_events: (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\python\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_train_80 = preprocess(df_final.loc[train_indexes].copy(),\"moda\",.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1568, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.loc[train_indexes].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(dtree, # Instancia de árbol a entrenar en cada fold\n",
    "                        df_train_80[feature_columns].values, # X_train features\n",
    "                        df_train_80[\"target\"].values, # Y_train targets\n",
    "                        scoring=scoring, # Pedimos que para fold se ejecute esta lista de scorings\n",
    "                        return_train_score = True, # Queremos ver los scorings de los training folds\n",
    "                        return_estimator = True, # Ademas, pedimos que se nos devuelvan los dtrees de entrenados\n",
    "                        cv=5, # Establecemos la cantidad de particiones para realizar la Validación cruzada\n",
    "                        n_jobs = -1 # Pedimos que se ejecute en paralelo, utilizando todos los cores\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00199485, 0.00299144, 0.00199485, 0.0009973 , 0.00199509]),\n",
       " 'score_time': array([0.00099802, 0.00099754, 0.00199437, 0.00199699, 0.00099921]),\n",
       " 'estimator': (DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best'),\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best'),\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best'),\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best'),\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best')),\n",
       " 'test_accuracy': array([0.68253968, 0.61290323, 0.63934426, 0.68852459, 0.62295082]),\n",
       " 'train_accuracy': array([0.71428571, 0.77235772, 0.79352227, 0.78947368, 0.74089069]),\n",
       " 'test_roc_auc': array([0.65592516, 0.61513514, 0.67555556, 0.73      , 0.67611111]),\n",
       " 'train_roc_auc': array([0.80637931, 0.83540457, 0.85073918, 0.8485352 , 0.83829513])}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_5_fold_resultados = pd.DataFrame(scores)\n",
    "cv_5_fold_resultados.drop([\"fit_time\",\"score_time\",\"estimator\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.655925</td>\n",
       "      <td>0.806379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.615135</td>\n",
       "      <td>0.835405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.850739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.848535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.740891</td>\n",
       "      <td>0.676111</td>\n",
       "      <td>0.838295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  train_accuracy  test_roc_auc  train_roc_auc\n",
       "0       0.682540        0.714286      0.655925       0.806379\n",
       "1       0.612903        0.772358      0.615135       0.835405\n",
       "2       0.639344        0.793522      0.675556       0.850739\n",
       "3       0.688525        0.789474      0.730000       0.848535\n",
       "4       0.622951        0.740891      0.676111       0.838295"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5_fold_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.762106</td>\n",
       "      <td>0.670545</td>\n",
       "      <td>0.835871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.034502</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>0.017729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.615135</td>\n",
       "      <td>0.806379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.740891</td>\n",
       "      <td>0.655925</td>\n",
       "      <td>0.835405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.838295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.676111</td>\n",
       "      <td>0.848535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.850739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_accuracy  train_accuracy  test_roc_auc  train_roc_auc\n",
       "count       5.000000        5.000000      5.000000       5.000000\n",
       "mean        0.649253        0.762106      0.670545       0.835871\n",
       "std         0.034502        0.033830      0.041458       0.017729\n",
       "min         0.612903        0.714286      0.615135       0.806379\n",
       "25%         0.622951        0.740891      0.655925       0.835405\n",
       "50%         0.639344        0.772358      0.675556       0.838295\n",
       "75%         0.682540        0.789474      0.676111       0.848535\n",
       "max         0.688525        0.793522      0.730000       0.850739"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5_fold_resultados.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtree_index = np.argmax(scores[\"test_accuracy\"]*scores[\"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_btree = scores[\"estimator\"][best_dtree_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_esperado = df_test.target.values\n",
    "y_pred = best_btree.predict(df_test[feature_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score validation: 0.6045918367346939\n"
     ]
    }
   ],
   "source": [
    "print(\"Score validation: \" + str(accuracy_score(y_esperado, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = StringIO()\n",
    "# export_graphviz(best_btree, out_file=dot_data,  \n",
    "#                 filled=True, rounded=True,\n",
    "#                 special_characters=True)\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Tolerancia al ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos una funcion que genera un array de un largo determinado con valores 0 y un porcentage de valores random. Los valores random que se generen van a depender de la media de la columna para la cual quiere generarse ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array_noise(elements_in_column, percentage_noise, mean_column):\n",
    "    \n",
    "    number_noise = round(elements_in_column*percentage_noise)\n",
    "    \n",
    "    mu, sigma = 0, mean_column\n",
    "    \n",
    "    noise = np.random.normal(mu, sigma, [number_noise,1])\n",
    "    \n",
    "    array_noise = noise.tolist()\n",
    "    \n",
    "    array_noise_final = []\n",
    "    \n",
    "    for item in array_noise:\n",
    "        \n",
    "        array_noise_final.append(item[0])\n",
    "    \n",
    "    array_no_noise = [0]*(elements_in_column - number_noise)\n",
    "    \n",
    "    noise = array_noise_final + array_no_noise\n",
    "    \n",
    "    random.shuffle(noise)\n",
    "    \n",
    "    return noise    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos una funcion que, utilizando la funcion anterior, agrega un % de ruido al atributo que indiquemos de un dataset determinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_with_noise(dataframe, name_attribute, percentage_noise):\n",
    "    \n",
    "    number_observations = len(dataframe[name_attribute].values)\n",
    "    \n",
    "    mean_column_attribute = dataframe[name_attribute].mean()\n",
    "    \n",
    "    array_noise = create_array_noise(number_observations, percentage_noise, mean_column_attribute)\n",
    "    \n",
    "    dataframe[name_attribute] = dataframe[name_attribute] + array_noise\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_btree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_best_model_point_2_family_datasets():\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como elegimos el mejor desicion tr\n",
    "\n",
    "def run_model_familiy_datasets(dataframe, model, array_noise, name_attribute):\n",
    "    \n",
    "    d = {'percentage_noise': array_noise}\n",
    "    \n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    array_accuracy = []\n",
    "    \n",
    "    array_roc_auc = []\n",
    "    \n",
    "    for noise in array_noise:\n",
    "        \n",
    "        # Generamos el dataset con noise\n",
    "        \n",
    "        df_noise = generate_dataset_with_noise(dataframe, name_attribute, noise)\n",
    "        \n",
    "        # Obtenemos las predicciones del mismo\n",
    "        \n",
    "        scoreing = ['accuracy','roc_auc']\n",
    "        \n",
    "        scores = cross_validate(model, # Instancia de árbol a entrenar en cada fold\n",
    "                        dataframe.drop(columns=['target']).values, # X_train features\n",
    "                        dataframe[\"target\"].values, # Y_train targets\n",
    "                        scoring=scoring, # Pedimos que para fold se ejecute esta lista de scorings\n",
    "                        return_train_score = True, # Queremos ver los scorings de los training folds\n",
    "                        return_estimator = True, # Ademas, pedimos que se nos devuelvan los dtrees de entrenados\n",
    "                        cv=5, # Establecemos la cantidad de particiones para realizar la Validación cruzada\n",
    "                        n_jobs = -1 # Pedimos que se ejecute en paralelo, utilizando todos los cores\n",
    "                       )\n",
    "                                \n",
    "        array_accuracy.append(sum(scores['test_accuracy'])/len(scores['test_accuracy']))\n",
    "                                \n",
    "        array_roc_auc.append(sum(scores['test_roc_auc'])/len(scores['test_roc_auc']))\n",
    "                    \n",
    "    df['accuracy'] = array_accuracy\n",
    "                                \n",
    "    df['roc_auc'] = array_roc_auc\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-2276e47cac2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0marray_of_noise_percentages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.35\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrun_model_familiy_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_btree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_of_noise_percentages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'diff_time_start_end'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-c80dcc6a212a>\u001b[0m in \u001b[0;36mrun_model_familiy_datasets\u001b[1;34m(dataframe, model, array_noise, name_attribute)\u001b[0m\n\u001b[0;32m     29\u001b[0m                        )\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0marray_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0marray_roc_auc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_roc_auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_roc_auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'test_accuracy'"
     ]
    }
   ],
   "source": [
    "array_of_noise_percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]\n",
    "\n",
    "run_model_familiy_datasets(df_train, best_btree, array_of_noise_percentages, 'diff_time_start_end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La performance del modelo no parece verse afectada por el noise. Puede ser porque no es una varaible importante para el mismo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Tenemos que usar todos los datos en df_train? Supongo que si\n",
    "\n",
    "# c) No entendi el tema de la profundidad\n",
    "\n",
    "# d) Tenemos que volver a entrar un modelo de arboles de decision y ver como performa?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (DONE) Genera que solo un % de los valores del array de noise tengan otroa valores que 0\n",
    "\n",
    "# (DONE) Elegir un atributo\n",
    "\n",
    "# b) \n",
    "\n",
    "# Tenemos que generar una familia de dataset con ruido\n",
    "\n",
    "# Tenemos que correr el mejor modelo del punto dos para cada familia (es decir, le pasamos df_train y vemos que predice)\n",
    "\n",
    "# Hacer un grafico con los resultados\n",
    "\n",
    "# c)\n",
    "\n",
    "# Tenemos que entrar modelos con cada dataset aplicando cross_validation\n",
    "\n",
    "# Ver como queda la altura del arbol en cada modelo\n",
    "\n",
    "# d)\n",
    "\n",
    "# Ver como performa cada uno de los modelos anteriores\n",
    "\n",
    "# Graficar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar Naive bayes sobre df_train usando la funcion de cross_validation\n",
    "\n",
    "# Predecir probabilidades target para df_test dado el modelo obtenido en el paso anterior\n",
    "\n",
    "# Probas condicionales: hacemos una funcion que nos devuelve para un atributo sus probabilidades condicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6173469387755102"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = df_train.drop(columns=['target'])\n",
    "\n",
    "Y = df_train['target']\n",
    "\n",
    "X_test = df_test.drop(columns=['target'])\n",
    "\n",
    "Y_test = df_test['target']\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.57075344e-06'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(float(5.57075344e-006))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.999994'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:f}'.format(9.99994429e-001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99994429e-001, 5.57075344e-006],\n",
       "       [3.21537725e-012, 1.00000000e+000],\n",
       "       [9.99996505e-001, 3.49514798e-006],\n",
       "       [9.99983502e-001, 1.64978363e-005],\n",
       "       [2.14742404e-021, 1.00000000e+000],\n",
       "       [1.00000000e+000, 3.01779191e-012],\n",
       "       [9.99999913e-001, 8.67107583e-008],\n",
       "       [1.71960840e-003, 9.98280392e-001],\n",
       "       [9.99999248e-001, 7.52454725e-007],\n",
       "       [6.08597914e-001, 3.91402086e-001],\n",
       "       [9.74582170e-001, 2.54178302e-002],\n",
       "       [1.78867045e-004, 9.99821133e-001],\n",
       "       [1.32381475e-020, 1.00000000e+000],\n",
       "       [9.99959162e-001, 4.08380082e-005],\n",
       "       [9.99406151e-001, 5.93848999e-004],\n",
       "       [9.99999947e-001, 5.29587246e-008],\n",
       "       [9.99979419e-001, 2.05813875e-005],\n",
       "       [9.99999992e-001, 8.34889431e-009],\n",
       "       [9.99999736e-001, 2.63596731e-007],\n",
       "       [9.85665686e-001, 1.43343141e-002],\n",
       "       [9.99995294e-001, 4.70600329e-006],\n",
       "       [9.99800033e-001, 1.99966761e-004],\n",
       "       [9.99991720e-001, 8.27962178e-006],\n",
       "       [1.65550264e-028, 1.00000000e+000],\n",
       "       [5.48520498e-018, 1.00000000e+000],\n",
       "       [9.95470264e-001, 4.52973584e-003],\n",
       "       [9.99999731e-001, 2.68710933e-007],\n",
       "       [9.99998826e-001, 1.17376385e-006],\n",
       "       [9.87275457e-001, 1.27245429e-002],\n",
       "       [9.99680146e-001, 3.19853987e-004],\n",
       "       [5.04200939e-094, 1.00000000e+000],\n",
       "       [1.00000000e+000, 2.33301744e-011],\n",
       "       [9.99996347e-001, 3.65273558e-006],\n",
       "       [9.91722455e-001, 8.27754534e-003],\n",
       "       [1.02297394e-010, 1.00000000e+000],\n",
       "       [9.55872035e-001, 4.41279648e-002],\n",
       "       [1.42154469e-001, 8.57845531e-001],\n",
       "       [9.99981979e-001, 1.80212905e-005],\n",
       "       [9.93686616e-001, 6.31338442e-003],\n",
       "       [3.84595259e-004, 9.99615405e-001],\n",
       "       [2.25440033e-018, 1.00000000e+000],\n",
       "       [9.99966844e-001, 3.31555198e-005],\n",
       "       [6.48738080e-005, 9.99935126e-001],\n",
       "       [5.00640521e-046, 1.00000000e+000],\n",
       "       [9.99997805e-001, 2.19512812e-006],\n",
       "       [9.99983272e-001, 1.67282960e-005],\n",
       "       [9.97712931e-001, 2.28706917e-003],\n",
       "       [9.99996565e-001, 3.43505519e-006],\n",
       "       [9.99999988e-001, 1.15064018e-008],\n",
       "       [9.94497381e-001, 5.50261935e-003],\n",
       "       [1.89472367e-018, 1.00000000e+000],\n",
       "       [9.99981114e-001, 1.88860299e-005],\n",
       "       [9.99586350e-001, 4.13650461e-004],\n",
       "       [9.97635179e-001, 2.36482126e-003],\n",
       "       [9.99771103e-001, 2.28897123e-004],\n",
       "       [9.99999980e-001, 2.03792364e-008],\n",
       "       [9.99994165e-001, 5.83525295e-006],\n",
       "       [1.24378066e-014, 1.00000000e+000],\n",
       "       [9.99981347e-001, 1.86526420e-005],\n",
       "       [1.64047821e-022, 1.00000000e+000],\n",
       "       [9.99996712e-001, 3.28829525e-006],\n",
       "       [1.49339065e-027, 1.00000000e+000],\n",
       "       [9.99977158e-001, 2.28422154e-005],\n",
       "       [9.95386308e-001, 4.61369189e-003],\n",
       "       [9.99870433e-001, 1.29567181e-004],\n",
       "       [1.71837974e-019, 1.00000000e+000],\n",
       "       [9.99999444e-001, 5.55766313e-007],\n",
       "       [9.99985087e-001, 1.49131404e-005],\n",
       "       [9.99999995e-001, 5.00907728e-009],\n",
       "       [8.05047259e-001, 1.94952741e-001],\n",
       "       [2.00840817e-004, 9.99799159e-001],\n",
       "       [5.79372093e-012, 1.00000000e+000],\n",
       "       [9.99934402e-001, 6.55984761e-005],\n",
       "       [9.99999497e-001, 5.02631258e-007],\n",
       "       [9.99982998e-001, 1.70024361e-005],\n",
       "       [9.99982498e-001, 1.75022524e-005],\n",
       "       [1.00000000e+000, 9.58977749e-011],\n",
       "       [1.42024324e-001, 8.57975676e-001],\n",
       "       [9.99998899e-001, 1.10099438e-006],\n",
       "       [9.82478439e-001, 1.75215611e-002],\n",
       "       [2.03893111e-002, 9.79610689e-001],\n",
       "       [9.99919280e-001, 8.07195202e-005],\n",
       "       [9.96253484e-039, 1.00000000e+000],\n",
       "       [9.99999143e-001, 8.57118299e-007],\n",
       "       [9.99998806e-001, 1.19420421e-006],\n",
       "       [9.99994903e-001, 5.09669412e-006],\n",
       "       [9.99188164e-001, 8.11836487e-004],\n",
       "       [9.78171389e-001, 2.18286108e-002],\n",
       "       [9.99495081e-001, 5.04919277e-004],\n",
       "       [9.99998038e-001, 1.96219128e-006],\n",
       "       [9.99967221e-001, 3.27785699e-005],\n",
       "       [9.99998741e-001, 1.25880641e-006],\n",
       "       [9.96158968e-001, 3.84103204e-003],\n",
       "       [9.99972853e-001, 2.71469726e-005],\n",
       "       [1.73705492e-005, 9.99982629e-001],\n",
       "       [9.99999998e-001, 1.83845832e-009],\n",
       "       [9.99990483e-001, 9.51683854e-006],\n",
       "       [9.99857034e-001, 1.42966057e-004],\n",
       "       [9.99980363e-001, 1.96371066e-005],\n",
       "       [9.99997454e-001, 2.54590205e-006],\n",
       "       [1.00000000e+000, 4.82760413e-010],\n",
       "       [9.76002303e-001, 2.39976966e-002],\n",
       "       [9.99949190e-001, 5.08102583e-005],\n",
       "       [9.99939264e-001, 6.07362628e-005],\n",
       "       [9.14933966e-001, 8.50660342e-002],\n",
       "       [9.97769869e-001, 2.23013067e-003],\n",
       "       [4.00432410e-001, 5.99567590e-001],\n",
       "       [8.57930386e-008, 9.99999914e-001],\n",
       "       [9.99992201e-001, 7.79863288e-006],\n",
       "       [9.99945937e-001, 5.40634407e-005],\n",
       "       [9.99760530e-001, 2.39470429e-004],\n",
       "       [9.99997576e-001, 2.42414169e-006],\n",
       "       [1.14114840e-001, 8.85885160e-001],\n",
       "       [1.18496361e-004, 9.99881504e-001],\n",
       "       [1.00000000e+000, 2.51318499e-014],\n",
       "       [9.99999968e-001, 3.21291651e-008],\n",
       "       [1.73367297e-036, 1.00000000e+000],\n",
       "       [9.99987573e-001, 1.24274499e-005],\n",
       "       [9.99994237e-001, 5.76347531e-006],\n",
       "       [9.99999337e-001, 6.62741905e-007],\n",
       "       [9.35672578e-001, 6.43274218e-002],\n",
       "       [9.99999998e-001, 2.42374256e-009],\n",
       "       [9.99869214e-001, 1.30785830e-004],\n",
       "       [9.99955922e-001, 4.40784866e-005],\n",
       "       [9.99994857e-001, 5.14348417e-006],\n",
       "       [9.99962247e-001, 3.77532481e-005],\n",
       "       [9.97340216e-001, 2.65978449e-003],\n",
       "       [9.97659891e-001, 2.34010947e-003],\n",
       "       [9.99999498e-001, 5.02166859e-007],\n",
       "       [1.00000000e+000, 3.59293543e-013],\n",
       "       [9.99991895e-001, 8.10464428e-006],\n",
       "       [2.76141872e-003, 9.97238581e-001],\n",
       "       [9.33429857e-001, 6.65701435e-002],\n",
       "       [6.39295214e-001, 3.60704786e-001],\n",
       "       [9.99524025e-001, 4.75974867e-004],\n",
       "       [3.38740317e-004, 9.99661260e-001],\n",
       "       [4.42917009e-014, 1.00000000e+000],\n",
       "       [9.99996216e-001, 3.78388387e-006],\n",
       "       [9.99268856e-001, 7.31143778e-004],\n",
       "       [9.99997332e-001, 2.66789169e-006],\n",
       "       [9.99965127e-001, 3.48728501e-005],\n",
       "       [9.99994323e-001, 5.67666423e-006],\n",
       "       [8.55319932e-002, 9.14468007e-001],\n",
       "       [9.96745879e-001, 3.25412095e-003],\n",
       "       [1.17180927e-011, 1.00000000e+000],\n",
       "       [9.99922319e-001, 7.76809534e-005],\n",
       "       [2.69795542e-017, 1.00000000e+000],\n",
       "       [9.93962937e-001, 6.03706290e-003],\n",
       "       [9.99974481e-001, 2.55194706e-005],\n",
       "       [9.94562870e-001, 5.43712981e-003],\n",
       "       [9.99660035e-001, 3.39964568e-004],\n",
       "       [9.99999771e-001, 2.28851923e-007],\n",
       "       [7.82221153e-003, 9.92177788e-001],\n",
       "       [9.85560399e-001, 1.44396006e-002],\n",
       "       [9.99999997e-001, 2.65558764e-009],\n",
       "       [5.15507968e-001, 4.84492032e-001],\n",
       "       [7.60693001e-060, 1.00000000e+000],\n",
       "       [9.99999999e-001, 5.21675704e-010],\n",
       "       [9.98761821e-001, 1.23817909e-003],\n",
       "       [9.99998861e-001, 1.13928290e-006],\n",
       "       [9.99999985e-001, 1.53471608e-008],\n",
       "       [2.47046654e-006, 9.99997530e-001],\n",
       "       [9.99992399e-001, 7.60091043e-006],\n",
       "       [9.99425692e-001, 5.74307696e-004],\n",
       "       [9.99999761e-001, 2.39347552e-007],\n",
       "       [2.31656487e-006, 9.99997683e-001],\n",
       "       [9.78785198e-001, 2.12148017e-002],\n",
       "       [9.99997714e-001, 2.28561563e-006],\n",
       "       [9.95363259e-001, 4.63674073e-003],\n",
       "       [9.99999449e-001, 5.50640639e-007],\n",
       "       [9.99373550e-001, 6.26449927e-004],\n",
       "       [9.99995082e-001, 4.91842807e-006],\n",
       "       [9.98407544e-001, 1.59245646e-003],\n",
       "       [9.99928783e-001, 7.12165152e-005],\n",
       "       [4.64102670e-023, 1.00000000e+000],\n",
       "       [9.99999505e-001, 4.95107500e-007],\n",
       "       [9.99999990e-001, 1.00220358e-008],\n",
       "       [9.99994608e-001, 5.39191423e-006],\n",
       "       [2.32500791e-089, 1.00000000e+000],\n",
       "       [9.99619047e-001, 3.80952611e-004],\n",
       "       [9.99999400e-001, 5.99889564e-007],\n",
       "       [9.99549930e-001, 4.50069751e-004],\n",
       "       [9.99869077e-001, 1.30923481e-004],\n",
       "       [1.56723056e-025, 1.00000000e+000],\n",
       "       [9.99992319e-001, 7.68121866e-006],\n",
       "       [9.99998972e-001, 1.02759124e-006],\n",
       "       [9.99570348e-001, 4.29651938e-004],\n",
       "       [9.99920189e-001, 7.98110566e-005],\n",
       "       [9.99998968e-001, 1.03242888e-006],\n",
       "       [3.03938940e-023, 1.00000000e+000],\n",
       "       [9.99999999e-001, 7.29670290e-010],\n",
       "       [2.05565354e-003, 9.97944346e-001],\n",
       "       [9.99533971e-001, 4.66029053e-004],\n",
       "       [9.99999479e-001, 5.20747957e-007],\n",
       "       [1.08519283e-011, 1.00000000e+000],\n",
       "       [4.73069939e-002, 9.52693006e-001],\n",
       "       [5.63644764e-001, 4.36355236e-001],\n",
       "       [1.66328193e-010, 1.00000000e+000],\n",
       "       [9.99997797e-001, 2.20342738e-006],\n",
       "       [9.99090665e-001, 9.09335369e-004],\n",
       "       [5.06304743e-036, 1.00000000e+000],\n",
       "       [9.99530042e-001, 4.69957739e-004],\n",
       "       [9.99999941e-001, 5.92709143e-008],\n",
       "       [9.93106313e-001, 6.89368710e-003],\n",
       "       [9.99998643e-001, 1.35661697e-006],\n",
       "       [9.99993954e-001, 6.04552430e-006],\n",
       "       [8.74338878e-001, 1.25661122e-001],\n",
       "       [9.99999973e-001, 2.74158239e-008],\n",
       "       [9.98288839e-001, 1.71116150e-003],\n",
       "       [9.94184160e-001, 5.81584010e-003],\n",
       "       [9.99999563e-001, 4.36721690e-007],\n",
       "       [3.63209453e-001, 6.36790547e-001],\n",
       "       [9.99999905e-001, 9.49486484e-008],\n",
       "       [9.97107268e-001, 2.89273199e-003],\n",
       "       [9.99682672e-001, 3.17328361e-004],\n",
       "       [3.91653316e-010, 1.00000000e+000],\n",
       "       [9.99938584e-001, 6.14160717e-005],\n",
       "       [9.94541224e-001, 5.45877646e-003],\n",
       "       [9.98748085e-001, 1.25191509e-003],\n",
       "       [1.84198938e-001, 8.15801062e-001],\n",
       "       [2.69323921e-062, 1.00000000e+000],\n",
       "       [1.27701263e-021, 1.00000000e+000],\n",
       "       [9.99922923e-001, 7.70771968e-005],\n",
       "       [9.99999926e-001, 7.44941993e-008],\n",
       "       [9.85817823e-001, 1.41821766e-002],\n",
       "       [9.99389908e-001, 6.10091533e-004],\n",
       "       [9.99946908e-001, 5.30922646e-005],\n",
       "       [9.99694033e-001, 3.05966893e-004],\n",
       "       [9.99999209e-001, 7.90819236e-007],\n",
       "       [4.83052831e-004, 9.99516947e-001],\n",
       "       [9.99999978e-001, 2.15287226e-008],\n",
       "       [9.99934041e-001, 6.59587129e-005],\n",
       "       [3.10564712e-018, 1.00000000e+000],\n",
       "       [9.80570051e-001, 1.94299494e-002],\n",
       "       [9.99998087e-001, 1.91334489e-006],\n",
       "       [9.99999995e-001, 5.30517331e-009],\n",
       "       [9.99999223e-001, 7.76550018e-007],\n",
       "       [9.99999240e-001, 7.59653522e-007],\n",
       "       [9.99999116e-001, 8.84310844e-007],\n",
       "       [9.99999968e-001, 3.20680929e-008],\n",
       "       [9.99998631e-001, 1.36948729e-006],\n",
       "       [3.95995663e-001, 6.04004337e-001],\n",
       "       [9.99962269e-001, 3.77307551e-005],\n",
       "       [9.98930044e-001, 1.06995608e-003],\n",
       "       [1.77685483e-015, 1.00000000e+000],\n",
       "       [9.99988673e-001, 1.13269893e-005],\n",
       "       [9.99998316e-001, 1.68374339e-006],\n",
       "       [9.99977896e-001, 2.21040785e-005],\n",
       "       [9.99999725e-001, 2.74644061e-007],\n",
       "       [2.00582347e-002, 9.79941765e-001],\n",
       "       [9.99863297e-001, 1.36702733e-004],\n",
       "       [6.66864900e-003, 9.93331351e-001],\n",
       "       [1.26210654e-008, 9.99999987e-001],\n",
       "       [9.99999234e-001, 7.65613467e-007],\n",
       "       [9.99999999e-001, 7.67911262e-010],\n",
       "       [9.99991629e-001, 8.37086985e-006],\n",
       "       [9.15800724e-001, 8.41992765e-002],\n",
       "       [9.99999993e-001, 6.51383748e-009],\n",
       "       [1.67091107e-006, 9.99998329e-001],\n",
       "       [9.99820530e-001, 1.79470030e-004],\n",
       "       [9.99999214e-001, 7.85626480e-007],\n",
       "       [1.21758019e-002, 9.87824198e-001],\n",
       "       [6.15971759e-005, 9.99938403e-001],\n",
       "       [9.99999915e-001, 8.49813946e-008],\n",
       "       [9.29128489e-005, 9.99907087e-001],\n",
       "       [9.99999572e-001, 4.27545426e-007],\n",
       "       [9.99953538e-001, 4.64618612e-005],\n",
       "       [9.99999998e-001, 1.50492619e-009],\n",
       "       [1.77977422e-002, 9.82202258e-001],\n",
       "       [9.99516121e-001, 4.83879371e-004],\n",
       "       [1.82382185e-019, 1.00000000e+000],\n",
       "       [9.99936519e-001, 6.34813792e-005],\n",
       "       [9.78563889e-001, 2.14361109e-002],\n",
       "       [1.16842088e-006, 9.99998832e-001],\n",
       "       [9.99999246e-001, 7.54387641e-007],\n",
       "       [9.99989195e-001, 1.08045581e-005],\n",
       "       [9.99998913e-001, 1.08739048e-006],\n",
       "       [1.18459884e-012, 1.00000000e+000],\n",
       "       [9.99237208e-001, 7.62792290e-004],\n",
       "       [9.99999993e-001, 6.80932713e-009],\n",
       "       [9.99999501e-001, 4.98930749e-007],\n",
       "       [9.99999995e-001, 5.47761563e-009],\n",
       "       [9.99909374e-001, 9.06257452e-005],\n",
       "       [9.42529622e-001, 5.74703778e-002],\n",
       "       [5.74555344e-004, 9.99425445e-001],\n",
       "       [1.00000000e+000, 1.97630760e-011],\n",
       "       [2.86811669e-008, 9.99999971e-001],\n",
       "       [9.99994736e-001, 5.26428330e-006],\n",
       "       [9.99999473e-001, 5.27121046e-007],\n",
       "       [9.99975726e-001, 2.42744473e-005],\n",
       "       [9.91191490e-001, 8.80850990e-003],\n",
       "       [9.99998919e-001, 1.08145962e-006],\n",
       "       [9.99999517e-001, 4.83406125e-007],\n",
       "       [9.99999998e-001, 2.12160283e-009],\n",
       "       [9.99999997e-001, 2.64051483e-009],\n",
       "       [6.09427265e-061, 1.00000000e+000],\n",
       "       [9.99999651e-001, 3.49001613e-007],\n",
       "       [9.99989442e-001, 1.05577682e-005],\n",
       "       [6.21033120e-068, 1.00000000e+000],\n",
       "       [9.99999700e-001, 2.99847112e-007],\n",
       "       [9.84600361e-001, 1.53996385e-002],\n",
       "       [9.99591501e-001, 4.08498749e-004],\n",
       "       [9.99996604e-001, 3.39649655e-006],\n",
       "       [1.20922107e-216, 1.00000000e+000],\n",
       "       [1.00000000e+000, 3.22829723e-016],\n",
       "       [9.99996308e-001, 3.69184714e-006],\n",
       "       [4.58750438e-001, 5.41249562e-001],\n",
       "       [9.99995570e-001, 4.43046336e-006],\n",
       "       [9.99740742e-001, 2.59257634e-004],\n",
       "       [9.99983591e-001, 1.64088693e-005],\n",
       "       [9.99998317e-001, 1.68274146e-006],\n",
       "       [4.95190659e-001, 5.04809341e-001],\n",
       "       [9.99999567e-001, 4.33404885e-007],\n",
       "       [9.83212375e-001, 1.67876254e-002],\n",
       "       [9.99998748e-001, 1.25152045e-006],\n",
       "       [4.31533369e-023, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.89351576e-015],\n",
       "       [1.65569176e-007, 9.99999834e-001],\n",
       "       [9.99995762e-001, 4.23799478e-006],\n",
       "       [9.99999997e-001, 2.66125411e-009],\n",
       "       [2.12298131e-017, 1.00000000e+000],\n",
       "       [9.99990900e-001, 9.09950851e-006],\n",
       "       [9.99999870e-001, 1.30274077e-007],\n",
       "       [9.98810983e-001, 1.18901721e-003],\n",
       "       [1.39615135e-003, 9.98603849e-001],\n",
       "       [1.00410427e-001, 8.99589573e-001],\n",
       "       [9.99976389e-001, 2.36105220e-005],\n",
       "       [9.99999947e-001, 5.27358564e-008],\n",
       "       [9.99999965e-001, 3.46649846e-008],\n",
       "       [9.99999642e-001, 3.57686940e-007],\n",
       "       [8.15829779e-065, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.07822175e-012],\n",
       "       [1.15014845e-002, 9.88498515e-001],\n",
       "       [8.79473502e-001, 1.20526498e-001],\n",
       "       [7.45858873e-006, 9.99992541e-001],\n",
       "       [7.72470554e-003, 9.92275294e-001],\n",
       "       [2.12139349e-006, 9.99997879e-001],\n",
       "       [9.99234096e-001, 7.65904021e-004],\n",
       "       [8.91362125e-033, 1.00000000e+000],\n",
       "       [9.99998705e-001, 1.29536786e-006],\n",
       "       [1.07110180e-004, 9.99892890e-001],\n",
       "       [5.93866865e-014, 1.00000000e+000],\n",
       "       [9.99977817e-001, 2.21833108e-005],\n",
       "       [9.99980706e-001, 1.92936314e-005],\n",
       "       [2.73844473e-001, 7.26155527e-001],\n",
       "       [1.16415178e-097, 1.00000000e+000],\n",
       "       [8.06313468e-012, 1.00000000e+000],\n",
       "       [2.70470953e-001, 7.29529047e-001],\n",
       "       [9.99999530e-001, 4.69756067e-007],\n",
       "       [8.53502871e-001, 1.46497129e-001],\n",
       "       [1.10163577e-002, 9.88983642e-001],\n",
       "       [9.99995423e-001, 4.57715322e-006],\n",
       "       [1.02032407e-002, 9.89796759e-001],\n",
       "       [9.97838019e-001, 2.16198094e-003],\n",
       "       [9.84164321e-001, 1.58356791e-002],\n",
       "       [6.45437369e-001, 3.54562631e-001],\n",
       "       [9.99996442e-001, 3.55848463e-006],\n",
       "       [1.26848426e-011, 1.00000000e+000],\n",
       "       [9.99998386e-001, 1.61443749e-006],\n",
       "       [9.99991035e-001, 8.96535057e-006],\n",
       "       [9.99996893e-001, 3.10674129e-006],\n",
       "       [3.16241725e-001, 6.83758275e-001],\n",
       "       [9.73879242e-001, 2.61207584e-002],\n",
       "       [5.62783500e-001, 4.37216500e-001],\n",
       "       [1.56640514e-011, 1.00000000e+000],\n",
       "       [7.69485984e-004, 9.99230514e-001],\n",
       "       [9.76380679e-001, 2.36193208e-002],\n",
       "       [9.99968657e-001, 3.13428384e-005],\n",
       "       [9.99994666e-001, 5.33423836e-006],\n",
       "       [9.99997953e-001, 2.04667894e-006],\n",
       "       [3.86647472e-005, 9.99961335e-001],\n",
       "       [9.97554976e-001, 2.44502428e-003],\n",
       "       [9.99999105e-001, 8.95243189e-007],\n",
       "       [9.99997374e-001, 2.62571956e-006],\n",
       "       [1.78771576e-022, 1.00000000e+000],\n",
       "       [1.45792188e-001, 8.54207812e-001],\n",
       "       [5.70939323e-001, 4.29060677e-001],\n",
       "       [9.99835606e-001, 1.64393700e-004],\n",
       "       [9.99999993e-001, 6.75110952e-009],\n",
       "       [1.00000000e+000, 1.24164385e-015],\n",
       "       [9.99999989e-001, 1.13307661e-008],\n",
       "       [4.02220290e-012, 1.00000000e+000],\n",
       "       [9.99988868e-001, 1.11317597e-005],\n",
       "       [9.99999875e-001, 1.25248392e-007],\n",
       "       [9.95540204e-001, 4.45979627e-003],\n",
       "       [9.99993113e-001, 6.88662435e-006],\n",
       "       [9.99998005e-001, 1.99457989e-006],\n",
       "       [9.99999245e-001, 7.55069084e-007],\n",
       "       [9.99395050e-001, 6.04950049e-004],\n",
       "       [9.99915532e-001, 8.44683095e-005],\n",
       "       [3.33648544e-018, 1.00000000e+000],\n",
       "       [9.99962216e-001, 3.77837743e-005]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_proba = clf.predict_proba(X_test)\n",
    "Y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizamos si hay datos faltantes en algun columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   column  number_nulls  percentage_nulls\n",
      "0                                 Android             0               0.0\n",
      "1                                Computer             0               0.0\n",
      "2                              Smartphone             0               0.0\n",
      "3                                  Tablet             0               0.0\n",
      "4                         ad campaign hit             0               0.0\n",
      "5                           brand listing             0               0.0\n",
      "6                                checkout             0               0.0\n",
      "7                              conversion             0               0.0\n",
      "8                         generic listing             0               0.0\n",
      "9                                     iOS             0               0.0\n",
      "10                                   lead             0               0.0\n",
      "11                      search engine hit             0               0.0\n",
      "12                      searched products             0               0.0\n",
      "13                             staticpage             0               0.0\n",
      "14                                 target             0               0.0\n",
      "15                         viewed product             0               0.0\n",
      "16                           visited site             0               0.0\n",
      "17                 diff_time_dayscheckout             0               0.0\n",
      "18               diff_time_daysconversion             0               0.0\n",
      "19                    diff_time_start_end             0               0.0\n",
      "20                        avg_time_events             0               0.0\n",
      "21           diff_time_days_minnone_in_q1             0               0.0\n",
      "22           diff_time_days_minnone_in_q2             0               0.0\n",
      "23           diff_time_days_minnone_in_q3             0               0.0\n",
      "24           diff_time_days_minnone_in_q4             0               0.0\n",
      "25  diff_time_dayssearch engine hit_in_q1             0               0.0\n",
      "26  diff_time_dayssearch engine hit_in_q2             0               0.0\n",
      "27  diff_time_dayssearch engine hit_in_q3             0               0.0\n",
      "28  diff_time_dayssearch engine hit_in_q4             0               0.0\n",
      "29                COUNT(users_logs)_in_q1             0               0.0\n",
      "..                                    ...           ...               ...\n",
      "52                                  is_5s             0               0.0\n",
      "53                                  is_6S             0               0.0\n",
      "54                           is_Galaxy J5             0               0.0\n",
      "55                                   is_7             0               0.0\n",
      "56                              is_7 Plus             0               0.0\n",
      "57                           is_Galaxy S8             0               0.0\n",
      "58                           is_Galaxy S7             0               0.0\n",
      "59                      is_Galaxy S7 Edge             0               0.0\n",
      "60                     is_Galaxy J7 Prime             0               0.0\n",
      "61                     is_Moto G2 3G Dual             0               0.0\n",
      "62                      is_Galaxy S6 Edge             0               0.0\n",
      "63                      is_Galaxy S6 Flat             0               0.0\n",
      "64                                  is_5c             0               0.0\n",
      "65                             is_6S Plus             0               0.0\n",
      "66                           is_Galaxy J7             0               0.0\n",
      "67                              is_6 Plus             0               0.0\n",
      "68                        is_Moto G4 Plus             0               0.0\n",
      "69                                  is_SE             0               0.0\n",
      "70           is_Galaxy Gran Prime Duos TV             0               0.0\n",
      "71                                  is_4S             0               0.0\n",
      "72                      is_Galaxy S8 Plus             0               0.0\n",
      "73                                   is_5             0               0.0\n",
      "74                          is_Moto G3 4G             0               0.0\n",
      "75                      is_Galaxy A5 2017             0               0.0\n",
      "76                 is_Moto X Play 4G Dual             0               0.0\n",
      "77                        is_Moto G5 Plus             0               0.0\n",
      "78                      is_Galaxy A7 2017             0               0.0\n",
      "79                             is_Moto X2             0               0.0\n",
      "80                           is_Galaxy A5             0               0.0\n",
      "81                         is_other_model             0               0.0\n",
      "\n",
      "[82 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def count_missing_data(dataframe):\n",
    "\n",
    "    series_nulls = dataframe.isnull().sum()\n",
    "\n",
    "    df_nulls = pd.DataFrame({'column': series_nulls.index, 'number_nulls': series_nulls.values})\n",
    "\n",
    "    def number_rows_parent_dataframe(dataframe):\n",
    "        return len(dataframe.index)\n",
    "\n",
    "    def missing_data_porcentage(value, dataframe=dataframe):\n",
    "        return value/number_rows_parent_dataframe(dataframe)*100\n",
    "\n",
    "    df_nulls['percentage_nulls'] = df_nulls['number_nulls'].apply(missing_data_porcentage)\n",
    "\n",
    "    return df_nulls\n",
    "\n",
    "print(count_missing_data(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el dataset de \"work\", a partir del cual vamos a obtener el dataset de training y el de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final_reduced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-c1d3029ef1b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_work\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_final_reduced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf_final_reduced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_work\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_final_reduced' is not defined"
     ]
    }
   ],
   "source": [
    "df_work = df_final_reduced.loc[~df_final_reduced.index.isin(df_test.index)]\n",
    "\n",
    "print(len(df_work.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work = df_work.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_work.index))\n",
    "\n",
    "df_work.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sacamos columnas que no son numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work = df_work.drop(columns=['person', 'model', 'marca', 'modelo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos una columna al dataset que indica a que fold pertenece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_number_fold(dataframe, number_folds):\n",
    "    \n",
    "    number_rows = len(dataframe.index)\n",
    "    \n",
    "    rows_per_fold = round(number_rows/number_folds)\n",
    "    \n",
    "    array_number_folds = []\n",
    "    \n",
    "    index = 1\n",
    "    \n",
    "    while index < (number_folds + 1):\n",
    "        \n",
    "        if (number_folds - index) == 1:\n",
    "            \n",
    "            array_numbers = [index] * (number_rows - rows_per_fold*index)\n",
    "        \n",
    "            array_number_folds = array_number_folds + array_numbers\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            array_numbers = [index] * rows_per_fold\n",
    "\n",
    "            array_number_folds = array_number_folds + array_numbers\n",
    "            \n",
    "        index = index + 1\n",
    "\n",
    "    dataframe['folds'] = array_number_folds\n",
    "    \n",
    "    return dataframe\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtramos por los folds que generamos con generate_number_fold() y vamos calculando las metricas que necesitamos tanto para training como para validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applied_cross_validation_dt(dataframe, number_folds, depth, criterion):\n",
    "    \n",
    "    df_folds = generate_number_fold(dataframe, number_folds)\n",
    "    \n",
    "    index = 1\n",
    "    \n",
    "    array_accuracy_training = []\n",
    "    \n",
    "    array_accuracy_val = []\n",
    "    \n",
    "    array_auc_training = []\n",
    "    \n",
    "    array_auc_val = []\n",
    "    \n",
    "    while index < (number_folds + 1):\n",
    "        \n",
    "        df_specific_fold = df_folds[df_folds['folds']==index].drop(columns=['folds'])\n",
    "        \n",
    "        X = df_specific_fold.drop(columns=['target'])\n",
    "\n",
    "        y = df_specific_fold['target']\n",
    "        \n",
    "        train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123)\n",
    "        \n",
    "        dtree=DecisionTreeClassifier(criterion=criterion, max_depth=depth)\n",
    "        \n",
    "        dtree.fit(train_X, train_y)\n",
    "        \n",
    "        predictions_val = dtree.predict(test_X)\n",
    "        predictions_train = dtree.predict(train_X)\n",
    "        \n",
    "        proba_val = dtree.predict_proba(test_X)\n",
    "        proba_train = dtree.predict_proba(train_X)\n",
    "        \n",
    "        acc_val = accuracy_score(test_y, predictions_val)\n",
    "        acc_train = accuracy_score(train_y, predictions_train)\n",
    "        \n",
    "        auc_val = roc_auc_score(test_y, proba_val[:,1])\n",
    "        auc_train = roc_auc_score(train_y, proba_train[:,1])\n",
    "        \n",
    "        array_accuracy_val.append(acc_val)\n",
    "        \n",
    "        array_accuracy_training.append(acc_train)\n",
    "        \n",
    "        array_auc_training.append(auc_val)\n",
    "    \n",
    "        array_auc_val.append(auc_train)\n",
    "        \n",
    "        index = index + 1\n",
    "    \n",
    "    return array_accuracy_training, array_accuracy_val, array_auc_training, array_auc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applied_cross_validation_dt(df_work, 5, 3, 'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table(acc_train, acc_val, auc_train, auc_val, criterion, depth, number_folds):\n",
    "    \n",
    "    d = {'acc_train': acc_train, 'acc_val': acc_val, 'auc_train': auc_train, 'auc_val': auc_val}\n",
    "    \n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    df['criterion'] = [criterion] * number_folds\n",
    "    \n",
    "    df['max_depth'] = [depth] * number_folds\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_gini = applied_cross_validation_dt(df_work, 5, 3, 'gini')[0]\n",
    "\n",
    "acc_val_gini = applied_cross_validation_dt(df_work, 5, 3, 'gini')[1]\n",
    "\n",
    "auc_train_gini = applied_cross_validation_dt(df_work, 5, 3, 'gini')[2]\n",
    "\n",
    "auc_val_gini = applied_cross_validation_dt(df_work, 5, 3, 'gini')[3]\n",
    "\n",
    "df_gini_3 = generate_table(acc_train_gini, acc_val_gini, auc_train_gini, auc_val_gini, 'Gini', 3, 5)\n",
    "\n",
    "df_gini_3 = df_gini_3.append(df_gini_3.mean(numeric_only=True), ignore_index=True)\n",
    "\n",
    "df_gini_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_total_row(s):\n",
    "    if s.B > 1.0:\n",
    "        return ['background-color: yellow']*5\n",
    " \n",
    "df.style.apply(highlight_greaterthan_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_gini = applied_cross_validation_dt(df_work, 5, 6, 'gini')[0]\n",
    "\n",
    "acc_val_gini = applied_cross_validation_dt(df_work, 5, 6, 'gini')[1]\n",
    "\n",
    "auc_train_gini = applied_cross_validation_dt(df_work, 5, 6, 'gini')[2]\n",
    "\n",
    "auc_val_gini = applied_cross_validation_dt(df_work, 5, 6, 'gini')[3]\n",
    "\n",
    "generate_table(acc_train_gini, acc_val_gini, auc_train_gini, auc_val_gini, 'Gini', 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
